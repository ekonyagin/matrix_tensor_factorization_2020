{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-C4EHZ9X7Hcg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchsummary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pQooCWOv7Ve4"
   },
   "outputs": [],
   "source": [
    "class resnet_test_data(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        self.files = sorted(os.listdir(dir))[:200]\n",
    "        self.dir = dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        df = pd.read_csv('ILSVRC2010_test_ground_truth.txt', index_col=False, header=None)\n",
    "        values = np.squeeze(df.values)[:200]\n",
    "        self.vals = values\n",
    "    def __getitem__(self, idx):\n",
    "        img = imread(os.path.join(self.dir, self.files[idx])) \n",
    "        class_id = self.vals[idx]\n",
    "        img = resize(img, (224,224))\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(class_id)\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_train_data(Dataset):\n",
    "    def __init__(self, dir):\n",
    "        self.files = sorted(os.listdir(dir))[200:]\n",
    "        self.dir = dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        df = pd.read_csv('ILSVRC2010_test_ground_truth.txt', index_col=False, header=None)\n",
    "        values = np.squeeze(df.values)[200:200+len(self.files)]\n",
    "        self.vals = values\n",
    "    def __getitem__(self, idx):\n",
    "        img = imread(os.path.join(self.dir, self.files[idx])) \n",
    "        class_id = self.vals[idx]\n",
    "        img = resize(img, (224,224))\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(class_id)\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pCaC_mhI8X0x"
   },
   "outputs": [],
   "source": [
    "dset = resnet_test_data(\"test_slice\")\n",
    "dset_train = resnet_train_data(\"test_slice/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "4QAnbuZ98YdR",
    "outputId": "21a7587f-9dce-4dc8-b2de-d574dfc7e440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "4ad719bf5b424bc8a86404ccb9b07db8",
      "1700551911f8481dbb75dbeac159f15c",
      "691218611b3a42c5a7634a90da3594f9",
      "43308b1a818647deab313c105169ebc2",
      "50e6997d7b4e464c8812d4161367f3f2",
      "7b64f0fdc5ec4dfa95e77681b9c20e59",
      "a8138abd48824ba4b1171353883c78c7",
      "fa05ee19e5e3471fba1e83480a9f5c4b"
     ]
    },
    "id": "sJMzRpUU-JO8",
    "outputId": "f6d87a0a-2b17-4b38-ecba-c100c3bb54f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "base_model = torchvision.models.resnet18(pretrained=True)\n",
    "base_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZZWB4uJy88Qb"
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dset, batch_size=200)\n",
    "train_loader = DataLoader(dset_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "ykMzwN0N9GoQ",
    "outputId": "15acf8a4-25e0-49d7-ac74-e919070fb4b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/egor_torch/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[489 671 823 299 555 987  56 281 738 938 942 299  82 738 457 858 299 666\n",
      " 462 988 493 858 657 645 133 374 469  71 449  45 467 670 414 644 788 674\n",
      " 118 527  94  70 621 986 286 112 897 703 457 649 589 645 631 450 786 387\n",
      "  40 180 674 637 424 111 873 211 777 681 338 417  32 289 841 808 309 788\n",
      " 892 831 909 422 551 800 393 408 671 776 162 738 467 564  72 187 420 515\n",
      " 154 652 841 852 439 663 510 975  90 856 584 601 815 936 275 518 652 997\n",
      " 233 988 939 559 425 570 122 886 116 300 118 894 407 629 755  54 313  11\n",
      " 800 640 540 564 738 326 322 386 955 793 647 732 582 990 875 804 557 551\n",
      " 759 309 767 687 447 723 877 451 583 987 772 618 496 324 422 984 375 301\n",
      "  38  81 757 151 905 973 644 599 418  35  84 233 437 453 311 792 537  25\n",
      " 488 607 564 286 818 946 669 317 613 751  66  40 961 446 371  71 400  47\n",
      " 971 546]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for x,y in data_loader:\n",
    "        x = x.cuda()\n",
    "\n",
    "        class_labels = np.argmax(base_model(x).cpu().detach().numpy(), axis=1)\n",
    "        print(class_labels)\n",
    "        #print(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Gk2A7cZe9n8W"
   },
   "outputs": [],
   "source": [
    "true_pred = class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(restored_conv, true_pred):\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "    model.layer4[1].conv1.weight.data = torch.tensor(restored_conv.reshape(512,512,3,3), dtype=torch.float32)\n",
    "    _ = model.cuda()\n",
    "    data_loader = DataLoader(dset, batch_size=200)\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_loader:\n",
    "            x = x.cuda()\n",
    "            class_labels = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
    "            acc = (class_labels == true_pred).sum()/200\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(10):\n",
    "        for x,y in data_loader:\n",
    "            with torch.no_grad():\n",
    "                x = x.cuda()\n",
    "\n",
    "                class_labels = np.argmax(base_model(x).cpu().detach().numpy(), axis=1)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            optimizer.zero_grad()\n",
    "            y = model(x)\n",
    "\n",
    "            loss = criterion(y, torch.tensor(class_labels).cuda())\n",
    "            loss.backward()\n",
    "            #print(loss)\n",
    "            optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_layers(core_factors, factors):\n",
    "    layers = [nn.Conv2d(in_channels=512,\n",
    "                       out_channels=r1,\n",
    "                       kernel_size=1),\n",
    "             nn.Conv2d(in_channels=r1,\n",
    "                      out_channels=r,\n",
    "                      kernel_size=1),\n",
    "             nn.Conv2d(in_channels=r,\n",
    "                      out_channels=r,\n",
    "                      groups=r,\n",
    "                      kernel_size=3),\n",
    "             nn.Conv2d(in_channels=r,\n",
    "                      out_channels=r2,\n",
    "                      kernel_size=1),\n",
    "             nn.Conv2d(in_channels=r2,\n",
    "                      out_channels=512,\n",
    "                      kernel_size=1)]\n",
    "    kernels = [torch.tensor(factors[0].T.reshape(r1, 512,1,1), dtype=torch.float32),\n",
    "                torch.tensor(core_factors[1].T.reshape(r,r1,1,1), dtype=torch.float32),\n",
    "                torch.tensor(core_factors[0].T.reshape(r,1, 3,3), dtype=torch.float32),\n",
    "                torch.tensor(core_factors[2].reshape(r2,r,1,1), dtype=torch.float32),\n",
    "                torch.tensor(factors[1].reshape(512,r2,1,1), dtype=torch.float32)]\n",
    "    for i in range(len(kernels)):\n",
    "        layers[i].weight = nn.Parameter(kernels[i])\n",
    "    model.layer4.conv1 =  nn.Sequential(*layers)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval():\n",
    "    data_loader = DataLoader(dset, batch_size=200)\n",
    "    for x,y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "\n",
    "            class_labels = np.argmax(model(x).cpu().detach().numpy(), axis=1)\n",
    "\n",
    "    return((class_labels == true_pred).sum()/200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Zj_Z3NE-9uUx",
    "outputId": "4fe0364b-40ee-46f2-af94-4ece0f46700a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/egor_torch/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.4714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(3.1231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.1922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(11.6931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(11.3160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(26.8412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(8.5117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.3729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(4.6144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.9527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.5615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.2096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.9298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.9073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.2840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(2.5393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.2955, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for r1 in (30,60,90):\n",
    "    acc[r1] = {}\n",
    "    for r2 in (30,60,90):\n",
    "        acc[r1][r2] = {}\n",
    "        for R in [100, 120, 150, 180, 240, 250]:\n",
    "            \n",
    "            core = np.load(f\"./decompositions/core_{r1}_{r2}_{R}.npy\")\n",
    "            factors = []\n",
    "            for i in range(2):\n",
    "                factors.append(np.load(f\"./decompositions/factor_{i}_{r1}_{r2}_{R}.npy\"))\n",
    "\n",
    "            core_weights = np.load(f\"./decompositions/core_weights_{r1}_{r2}_{R}.npy\")\n",
    "            core_factors = []\n",
    "            for i in range(3):\n",
    "                core_factors.append(np.load(f\"./decompositions/core_factor_{i}_{r1}_{r2}_{R}.npy\"))\n",
    "            core_factors = tuple(core_factors)\n",
    "            \n",
    "            model = torchvision.models.resnet18(pretrained=True)\n",
    "            r = R\n",
    "            replace_layers(core_factors, factors)\n",
    "            fine_tune()\n",
    "            acc[r1][r2][R] = eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"acc.pickle\", \"wb\") as f:\n",
    "    pickle.dump(acc, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_layers(core_factors, factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{30: {30: {100: 1.0, 120: 1.0, 150: 1.0, 180: 1.0, 240: 0.0, 250: 0.0},\n",
       "  60: {100: 1.0, 120: 0.995, 150: 0.995, 180: 0.995, 240: 1.0, 250: 0.995},\n",
       "  90: {100: 1.0, 120: 0.995, 150: 0.985, 180: 1.0, 240: 0.985, 250: 0.99}},\n",
       " 60: {30: {100: 0.96, 120: 0.935, 150: 0.3, 180: 0.0, 240: 0.0, 250: 0.0},\n",
       "  60: {100: 0.985, 120: 1.0, 150: 0.45, 180: 0.99, 240: 1.0, 250: 1.0},\n",
       "  90: {100: 1.0, 120: 1.0, 150: 0.94, 180: 0.985, 240: 0.93, 250: 1.0}},\n",
       " 90: {30: {100: 0.015, 120: 0.02, 150: 0.01, 180: 0.06, 240: 0.0, 250: 0.0},\n",
       "  60: {100: 0.98, 120: 0.975, 150: 0.64, 180: 0.3, 240: 0.87, 250: 0.78},\n",
       "  90: {100: 0.915, 120: 0.51, 150: 0.745, 180: 0.755, 240: 0.63, 250: 0.79}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1700551911f8481dbb75dbeac159f15c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43308b1a818647deab313c105169ebc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa05ee19e5e3471fba1e83480a9f5c4b",
      "placeholder": "​",
      "style": "IPY_MODEL_a8138abd48824ba4b1171353883c78c7",
      "value": " 44.7M/44.7M [03:03&lt;00:00, 255kB/s]"
     }
    },
    "4ad719bf5b424bc8a86404ccb9b07db8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_691218611b3a42c5a7634a90da3594f9",
       "IPY_MODEL_43308b1a818647deab313c105169ebc2"
      ],
      "layout": "IPY_MODEL_1700551911f8481dbb75dbeac159f15c"
     }
    },
    "50e6997d7b4e464c8812d4161367f3f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "691218611b3a42c5a7634a90da3594f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b64f0fdc5ec4dfa95e77681b9c20e59",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50e6997d7b4e464c8812d4161367f3f2",
      "value": 46827520
     }
    },
    "7b64f0fdc5ec4dfa95e77681b9c20e59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8138abd48824ba4b1171353883c78c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa05ee19e5e3471fba1e83480a9f5c4b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
