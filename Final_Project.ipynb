{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.cuda()\n",
    "summary(resnet18, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resnet18.named_parameters():\n",
    "    print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = resnet18.layer4[1].conv1.weight.data.detach().cpu().clone().numpy()\n",
    "Y = Y.reshape(512,512,9).transpose([2,0,1])\n",
    "Y = np.transpose(Y, [1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 50\n",
    "R1, R2 = 30,30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.diag(np.ones(90))[:,:R1]\n",
    "V = np.diag(np.ones(90))[:,:R2]\n",
    "A = np.random.randn(R1,R)\n",
    "B = np.random.randn(R2,R)\n",
    "C = np.random.randn(9,R)\n",
    "\n",
    "#Y_restored = np.transpose(tl.kruskal_to_tensor((np.ones(R), (U@A, V@B, C))), [0,1,2])\n",
    "\n",
    "#print(\"Random tensors. Norm is\", np.linalg.norm(Y-Y_restored))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y1 = tl.unfold(core,0)\n",
    "for i in range(20):\n",
    "    #print(\"Relative Norm is\", np.linalg.norm((U@A @ (tl.tenalg.khatri_rao([C, V@B])).T) - Y1)/\\\n",
    "         # np.linalg.norm(Y1))\n",
    "    A = U.T @ tl.unfold(core,0) @ (tl.tenalg.khatri_rao([C, V@B])) @ np.linalg.inv(C.T@C * (B.T@B))\n",
    "    Q = tl.unfold(core,0) @ (tl.tenalg.khatri_rao([C, V@B]))@ np.linalg.inv((C.T@C * (B.T@B))) @\\\n",
    "        tl.tenalg.khatri_rao([C, V@B]).T @ tl.unfold(core,0).T\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eigh(Q)\n",
    "    indices = np.argsort(np.abs(eigvals))[-R1:]\n",
    "    \n",
    "    U = eigvecs[:,indices]\n",
    "    \n",
    "    B = V.T @ tl.unfold(core,1) @ (tl.tenalg.khatri_rao([C, U@A])) @ np.linalg.inv(C.T@C * (A.T@A))\n",
    "    \"\"\"\n",
    "    R_ = tl.unfold(core,1) @ tl.tenalg.khatri_rao([C, U@A]) @ np.linalg.inv(C.T@C * (A.T@A)) @ \\\n",
    "        tl.tenalg.khatri_rao([C, U@A]).T@tl.unfold(core,1).T\n",
    "    eigvals, eigvecs = np.linalg.eig(R_)\n",
    "    indices = np.argsort(np.abs(eigvals))[-R2:]\n",
    "    V = eigvecs[:,indices]\n",
    "    \n",
    "    C = tl.unfold(core,2) @ (tl.tenalg.khatri_rao([U@A, V@B])) @ np.linalg.inv(B.T@B * (A.T@A))\n",
    "    #C[C < 0] = 0\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"Relative Norm is\", np.linalg.norm((U@A @ (tl.tenalg.khatri_rao([C, V@B])).T) - Y1)/\\\n",
    "          np.linalg.norm(Y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKD-CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.decomposition import partial_tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = resnet18.layer4[1].conv1.weight.data.detach().cpu().clone().numpy()\n",
    "Y = Y.reshape(512, 512, 9)\n",
    "Y = Y.transpose((2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_compression(Y, r1,r2,R):\n",
    "    core, factors = partial_tucker(Y, \n",
    "                                   modes=[1,2],\n",
    "                                   ranks=[r1,r2],\n",
    "                                   n_iter_max=200, \n",
    "                                   tol=1e-6)\n",
    "    np.save(f\"core_{r1}_{r2}_{R}\", core)\n",
    "    print(\"core:\", core.shape)\n",
    "    for i in range(len(factors)):\n",
    "        np.save(f\"factor_{i}_{r1}_{r2}_{R}\" , factors[i])\n",
    "        print(\"fi\",factors[i].shape)\n",
    "    core_weights, core_factors = tl.decomposition.parafac(core,\n",
    "                             rank=R, \n",
    "                             n_iter_max=5000,\n",
    "                             tol=1e-7)\n",
    "    #print(type(core_factors), len(core_factors))\n",
    "    np.save(f\"core_weights_{r1}_{r2}_{R}\", core_weights)\n",
    "    #print(\"core weights:\", core_weights.shape)\n",
    "    for i in range(len(core_factors)):\n",
    "        print(\"core fac\", core_factors[i].shape)\n",
    "        np.save(f\"core_factor_{i}_{r1}_{r2}_{R}\", core_factors[i])\n",
    "        #print(\"core fact:\", core_factors[i].shape)\n",
    "    restored_core = tl.kruskal_to_tensor((core_weights, core_factors))\n",
    "    #print(\"rest core:\", restored_core.shape)\n",
    "    np.linalg.norm(core-restored_core)/np.linalg.norm(core)\n",
    "\n",
    "    restored_conv = np.zeros_like(Y)\n",
    "    restored_conv = np.zeros_like(Y)\n",
    "    for i in range(9):\n",
    "        restored_conv[i] = tl.tucker_to_tensor((restored_core[i], factors))\n",
    "\n",
    "    return np.linalg.norm(restored_conv-Y)/np.linalg.norm(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = {}\n",
    "for R in [100]:\n",
    "    norm = conduct_compression(Y, 90,80,R)\n",
    "    norms[R] = norm\n",
    "norms_aggr[\"90 90\"] = norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = {}\n",
    "for R in [100, 120, 150, 180, 210, 240, 250, 280, 300, 330, 380, 400]:\n",
    "    norm = conduct_compression(Y, 90,90,R)\n",
    "    norms[R] = norm\n",
    "norms_aggr[\"90 90\"] = norqms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv *.npy ./decomp_60/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r1 in (60,):\n",
    "    print()\n",
    "    print(\"r1 is \", r1, end=\"\")\n",
    "    for r2 in (30,60,90):\n",
    "        print(r2, end = \" \")\n",
    "        for R in [100, 120, 150, 180, 240, 250]:\n",
    "            norm = conduct_compression(Y, r1, r2,R)\n",
    "            norms[R] = norm\n",
    "        norms_aggr[str(r1) +\" \"+str(r2)] = norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for i in list(norms.keys()):\n",
    "    vals.append(norms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.grid()\n",
    "plt.plot(list(norms.keys()),vals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(r1,r2,R):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.exists(\"./decompositions/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r1 in (30,60,90):\n",
    "    for r2 in (30,60,90):\n",
    "        for R in [100, 120, 150, 180, 240, 250]:\n",
    "            assert os.path.exists(f\"./decompositions/core_{r1}_{r2}_{R}.npy\")\n",
    "            print(r1,r2,R)\n",
    "            for i in range(2):\n",
    "                print(i)\n",
    "                assert os.path.exists(f\"./decompositions/factor_{i}_{r1}_{r2}_{R}.npy\")\n",
    "            assert os.path.exists(f\"./decompositions/core_weights_{r1}_{r2}_{R}.npy\")\n",
    "            for i in range(3):\n",
    "                assert os.path.exists(f\"./decompositions/core_factor_{i}_{r1}_{r2}_{R}.npy\")\n",
    "\"\"\"\n",
    "core = np.load(f\"./decompositions/core_{r1}_{r2}_{R}.npy\")\n",
    "factors = []\n",
    "for i in range(3):\n",
    "        factors.append(np.load(f\"./decompositions/factor_{i}_{r1}_{r2}_{R}.npy\"))\n",
    "\n",
    "core_weights = np.load(f\"./decompositions/core_weights_{r1}_{r2}_{R}.npy\")\n",
    "core_factors = []\n",
    "for i in range(2):\n",
    "    core_factors.append(np.load(f\"./decompositions/core_factor_{i}_{r1}_{r2}_{R}.npy\"))\n",
    "core_factors = tuple(core_factors)\n",
    "restored_core = tl.kruskal_to_tensor((core_weights, core_factors))\n",
    "print(restored_core.shape)\n",
    "    #np.linalg.norm(core-restored_core)/np.linalg.norm(core)\n",
    "restored_conv = np.zeros_like(Y)\n",
    "print(restored_conv.shape)\n",
    "for i in range(9):\n",
    "    print(i)\n",
    "    restored_conv[i] = tl.tucker_to_tensor((restored_core[i], factors))\n",
    "\n",
    "\n",
    "\"\"\"           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=512,\n",
    "                             out_channels=512,\n",
    "                             kernel_size=3)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = SimpleConv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((64,512,8,8),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "conv_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "conv_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedConv(nn.Module):\n",
    "    def __init__(self, cin, cout, r1,r2,r, D=3):\n",
    "        super(CompressedConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=cin,\n",
    "                              out_channels=r1,\n",
    "                              kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=r1,\n",
    "                              out_channels=r,\n",
    "                              kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=r,\n",
    "                              out_channels=r,\n",
    "                              kernel_size=D)\n",
    "        self.conv4 = nn.Conv2d(in_channels=r,\n",
    "                              out_channels=r2,\n",
    "                              kernel_size=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=r2,\n",
    "                              out_channels=cout,\n",
    "                              kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_conv = CompressedConv(512,512,90,90,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "x = torch.randn((64,512,8,8),)\n",
    "compressed_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountSpeed(r1,r2,r, dev=\"cpu\"):\n",
    "    if dev==\"cpu\":\n",
    "        compressed_conv = CompressedConv(512,512,r1,r2,r)\n",
    "    x = torch.randn((64,512,8,8),)\n",
    "    if dev==\"cuda\":\n",
    "        compressed_conv = CompressedConv(512,512,r1,r2,r).cuda()\n",
    "        x = x.cuda()\n",
    "    start = dt.datetime.now()\n",
    "    cycles = 100\n",
    "    for i in range(100):\n",
    "        y = compressed_conv(x)\n",
    "        y = y +1\n",
    "    finish = dt.datetime.now()\n",
    "    total_time = (finish-start).total_seconds()/cycles\n",
    "    return total_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountSpeed(90,90,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountSpeed_simple(r1,r2,r, dev=\"cpu\"):\n",
    "    if dev==\"cpu\":\n",
    "        compressed_conv = SimpleConv()\n",
    "    x = torch.randn((64,512,8,8),)\n",
    "    if dev==\"cuda\":\n",
    "        compressed_conv = CompressedConv(512,512,r1,r2,r).cuda()\n",
    "        x = x.cuda()\n",
    "    start = dt.datetime.now()\n",
    "    cycles = 100\n",
    "    for i in range(100):\n",
    "        y = compressed_conv(x)\n",
    "        y = y +1\n",
    "    finish = dt.datetime.now()\n",
    "    total_time = (finish-start).total_seconds()/cycles\n",
    "    return total_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountSpeed_simple(90,90,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.zeros((3,3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r1 in enumerate((30, 60, 90)):\n",
    "    for j,r2 in enumerate((30,60, 90)):\n",
    "        for k,r in enumerate((100, 120, 150, 180, 240, 250)):\n",
    "            time[i,j,k] = CountSpeed(r1,r2,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"time_cpu\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_gpu = np.zeros((3,3,6))\n",
    "for i,r1 in enumerate((30, 60, 90)):\n",
    "    for j,r2 in enumerate((30,60, 90)):\n",
    "        for k,r in enumerate((100, 120, 150, 180, 240, 250)):\n",
    "            time_gpu[i,j,k] = CountSpeed(r1,r2,r, dev='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"time_gpu\", time_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"decomp_60.pickle\", \"wb\") as f:\n",
    "    pickle.dump(norms_aggr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filename.pickle\", \"rb\") as f:\n",
    "    a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompressionRate(r1,r2,R):\n",
    "    s = 9*r1*r2 + 512*(r1+r2) + 9*R + R*(r1+r2)\n",
    "    init = 512*512*9.\n",
    "    return init/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompressionRate(90, 90, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
